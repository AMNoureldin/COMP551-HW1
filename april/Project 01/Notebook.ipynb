{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "## SETTINGS\n",
    "plt.style.use('dark_background')\n",
    "#cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "#cmap_bold = ['darkorange', 'c', 'darkblue']\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "def pow(n,m): return np.float_power(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADULT DATA\n",
    "adult_names = ['age', 'workclass', 'fnlwgt', 'education', \n",
    "               'education-num', 'marital-status', 'occupation', \n",
    "               'relationship', 'race', 'sex', 'capital-gain', \n",
    "               'capital-loss', 'hours-per-week', 'native-country', 'Y']\n",
    "# Original sets\n",
    "adult = pd.read_csv('Adult/adult.data', names=adult_names, sep=',')\n",
    "\n",
    "\n",
    "# Setup for One Hot Enconding\n",
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', \n",
    "      OneHotEncoder(categories='auto', \n",
    "                    sparse=False, handle_unknown='ignore'), \n",
    "      [1,3,5,6,7,8,9,13])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ct2 = ColumnTransformer(\n",
    "  [('one_hot_encoder',\n",
    "    OneHotEncoder(categories='auto',\n",
    "                  sparse=False, handle_unknown='ignore'),\n",
    "    [0])],\n",
    "  remainder='passthrough'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df, model=KNeighborsClassifier, model_params={\"n_neighbors\": 5}):\n",
    "    folds = split(df)\n",
    "    val_results = []\n",
    "    trn_results = []\n",
    "    for train, validate in folds:\n",
    "        training, training_labels = train\n",
    "        validation, validation_labels = validate\n",
    "        mdl = model(**model_params)\n",
    "        mdl = mdl.fit(training, training_labels)\n",
    "        trn_results.append(mdl.score(training, training_labels))\n",
    "        val_results.append(mdl.score(validation, validation_labels))\n",
    "    return val_results, trn_results\n",
    "\n",
    "\n",
    "def split(df):\n",
    "    y = df[df.shape[1]-1]\n",
    "    X = df.drop(df.shape[1]-1, axis=1)\n",
    "    folds = []\n",
    "    rows = X.shape[0]\n",
    "    for fold in np.array_split(range(rows), 5):\n",
    "        validate_data = X.loc[fold[0]: fold[-1]]\n",
    "        validate_labels = y.loc[fold[0]: fold[-1]]\n",
    "        train_data = X.drop(X.index[fold[0]: fold[-1]])\n",
    "        train_labels = y.drop(y.index[fold[0]: fold[-1]])\n",
    "        folds.append(((train_data, train_labels),\n",
    "                      (validate_data, validate_labels)))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate2(df, model=KNeighborsClassifier, model_params={\"n_neighbors\": 5}):\n",
    "    folds = split2(df)\n",
    "    val_results = []\n",
    "    trn_results = []\n",
    "    for train, validate in folds:\n",
    "        training, training_labels = train\n",
    "        validation, validation_labels = validate\n",
    "        mdl = model(**model_params)\n",
    "        mdl = mdl.fit(training, training_labels)\n",
    "        trn_results.append(mdl.score(training, training_labels))\n",
    "        val_results.append(mdl.score(validation, validation_labels))\n",
    "    return val_results, trn_results\n",
    "\n",
    "def split2(df):\n",
    "    y = df[0]\n",
    "    X = df.drop(0, axis=1)\n",
    "    folds = []\n",
    "    rows = X.shape[0]\n",
    "    for fold in np.array_split(range(rows), 5):\n",
    "        validate_data = X.loc[fold[0]: fold[-1]]\n",
    "        validate_labels = y.loc[fold[0]: fold[-1]]\n",
    "        train_data = X.drop(X.index[fold[0]: fold[-1]])\n",
    "        train_labels = y.drop(y.index[fold[0]: fold[-1]])\n",
    "        folds.append(((train_data, train_labels),\n",
    "                      (validate_data, validate_labels)))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_sample(df, samples):\n",
    "    df = df[~(df.values == ' ?').any(1)]\n",
    "    df = df.sample(n=samples)\n",
    "    cols = df.shape[1]-1\n",
    "    df_X = df.iloc[:, 0:cols]\n",
    "    df_Y = df.iloc[:, cols]\n",
    "    enc_df = pd.DataFrame(ct.fit_transform(df_X, df_Y))\n",
    "    vals, trains = cross_validate(enc_df)\n",
    "    return np.mean(vals), np.mean(trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_letters(df, samples):\n",
    "    df = df.sample(n=samples)\n",
    "    enc_df = pd.DataFrame(ct2.fit_transform(df))\n",
    "    vals, trains = cross_validate2(enc_df)\n",
    "    return np.mean(vals), np.mean(trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 295, 581, 866, 1152, 1437, 1723, 2008, 2294, 2579, 2865, 3150, 3436, 3721, 4007, 4292, 4578, 4863, 5149, 5434, 5720, 6005, 6291, 6576, 6862, 7147, 7433, 7718, 8004, 8289, 8575, 8860, 9146, 9431, 9717, 10002, 10288, 10573, 10859, 11144, 11430, 11715, 12001, 12286, 12572, 12857, 13143, 13428, 13714, 14000]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samples = np.linspace(10, 14000, 50)\n",
    "samples = [int(n) for n in samples.tolist()]\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_tr_results = []\n",
    "adult_vl_results = []\n",
    "for n in samples:\n",
    "    val, trn = cross_validate_sample(adult, n)\n",
    "    adult_vl_results.append(val)\n",
    "    adult_tr_results.append(trn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_test = pd.read_csv('Adult/adult.test', names=adult_names, sep=',', header=1)\n",
    "\n",
    "adult_test_vl_results = []\n",
    "adult_test_tr_results = []\n",
    "\n",
    "for n in samples:\n",
    "    val, trn = cross_validate_sample(adult_test, n)\n",
    "    adult_test_vl_results.append(val)\n",
    "    adult_test_tr_results.append(trn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_names = ['lettr', 'x-box', 'y-box', 'width', 'high', 'onpix', \n",
    "                 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr',\n",
    "                 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
    "letters = pd.read_csv('Letter/letter-recognition.data', names=letters_names, sep=',')\n",
    "\n",
    "letters_tr_results = []\n",
    "letters_vl_results = []\n",
    "for n in samples:\n",
    "    val, trn = cross_validate_letters(letters, n)\n",
    "    letters_tr_results.append(trn)\n",
    "    letters_vl_results.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = samples\n",
    "\n",
    "# Adult data\n",
    "adult_tr_std = np.std(adult_tr_results)\n",
    "adult_vl_std = np.std(adult_vl_results)\n",
    "# Adult test\n",
    "adult_test_tr_std = np.std(adult_test_tr_results)\n",
    "adult_test_vl_std = np.std(adult_test_vl_results)\n",
    "# Letter data\n",
    "letters_tr_std = np.std(letters_tr_results)\n",
    "letters_vl_std = np.std(letters_vl_results)\n",
    "# polyfit\n",
    "a0, a1, a2 = np.polyfit(t, adult_tr_results, deg=2)\n",
    "b0, b1, b2 = np.polyfit(t, adult_vl_results, deg=2)\n",
    "c0, c1, c2 = np.polyfit(t, adult_test_tr_results, deg=2)\n",
    "d0, d1, d2 = np.polyfit(t, adult_test_vl_results, deg=2)\n",
    "e0, e1, e2 = np.polyfit(t, letters_tr_results, deg=2)\n",
    "f0, f1, f2 = np.polyfit(t, letters_vl_results, deg=2)\n",
    "\n",
    "fun0 = a0*np.power(t,2) + a1*np.power(t,1) + a2*np.power(t,0)\n",
    "fun1 = b0*np.power(t,2) + b1*np.power(t,1) + b2*np.power(t,0)\n",
    "fun2 = c0*np.power(t,2) + c1*np.power(t,1) + c2*np.power(t,0)\n",
    "fun3 = d0*np.power(t,2) + d1*np.power(t,1) + d2*np.power(t,0)\n",
    "fun4 = e0*np.power(t,2) + e1*np.power(t,1) + e2*np.power(t,0)\n",
    "fun5 = f0*np.power(t,2) + f1*np.power(t,1) + f2*np.power(t,0)\n",
    "\n",
    "fig = plt.figure(figsize=(8,15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "ax0, ax1, ax2 = fig.subplots(3)\n",
    "\n",
    "ax0.set_title(\"Probability of an adult having a >50K$ income as a function of Adult data\")\n",
    "ax0.grid()\n",
    "ax0.set_xlabel('Number of samples')\n",
    "ax0.set_ylabel('Probability of having more than $50K')\n",
    "\n",
    "ax0.scatter(t, adult_tr_results, c='cyan', \n",
    "           label='Adult Training Data' )\n",
    "ax0.scatter(t, adult_vl_results, c='orange',\n",
    "           label='Adult Validation Data')\n",
    "ax0.plot(t,fun0, linewidth=1, color='cyan')\n",
    "ax0.plot(t,fun1, linewidth=2, color='orange')\n",
    "\n",
    "ax0.fill_between(t, adult_tr_results-adult_tr_std, adult_tr_results+adult_tr_std, alpha=0.25, color='cyan')\n",
    "ax0.fill_between(t, adult_vl_results-adult_vl_std, adult_vl_results+adult_vl_std, alpha=0.25, color='orange')\n",
    "ax0.legend()\n",
    "\n",
    "ax1.set_title(\"Probability of an adult having a >50K$ income as a function of Adult test data\")\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Number of samples')\n",
    "ax1.set_ylabel('Probability of having more than $50K')\n",
    "\n",
    "ax1.scatter(t, adult_test_tr_results, c='cyan', \n",
    "           label='Adult Test Training Data' )\n",
    "ax1.scatter(t, adult_test_vl_results, c='orange',\n",
    "           label='Adult Test Validation Data')\n",
    "ax1.plot(t,fun2, linewidth=1, color='cyan')\n",
    "ax1.plot(t,fun3, linewidth=2, color='orange')\n",
    "\n",
    "ax1.fill_between(t, adult_test_tr_results-adult_test_tr_std, adult_test_tr_results+adult_tr_std, alpha=0.25, color='cyan')\n",
    "ax1.fill_between(t, adult_test_vl_results-adult_test_vl_std, adult_test_vl_results+adult_vl_std, alpha=0.25, color='orange')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title(\"Probability of letter recognition as a function of sample size\")\n",
    "ax2.grid()\n",
    "ax2.scatter(t, letters_tr_results, c='greenyellow',\n",
    "           label='Letter Recognition Training Data')\n",
    "ax2.scatter(t, letters_vl_results, c='cyan',\n",
    "           label='Letter Recognition Validation Data')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Number of samples')\n",
    "ax2.set_ylabel('Probability that letter is recognized')\n",
    "\n",
    "ax2.plot(t,fun4, linewidth=2, color='greenyellow')\n",
    "ax2.plot(t,fun5, linewidth=2, color='cyan')\n",
    "ax2.fill_between(t, letters_tr_results-letters_tr_std, letters_tr_results+letters_tr_std, alpha=0.25, color='greenyellow')\n",
    "ax2.fill_between(t, letters_vl_results-letters_vl_std, letters_vl_results+letters_vl_std, alpha=0.25, color='greenyellow')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84e1b13578238f73f2a27b11057f0c18916d719a901af525a1038a17e0c745b0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
